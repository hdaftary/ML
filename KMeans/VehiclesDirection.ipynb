{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VehiclesDirection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQ/1IqCqFjz4CMm13MFUzy"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtp9Y2lsw6E-"
      },
      "source": [
        "import json, requests, io, zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, precision_recall_curve, roc_curve\n",
        "\n",
        "username = 'HDaftary'\n",
        "token = '<<secret>>'\n",
        "session = requests.Session()\n",
        "session.auth = (username, token)\n",
        "\n",
        "# providing raw url to download data zip from github\n",
        "zip_url = 'https://raw.githubusercontent.com/HDaftary97/ML/main/KMeans/data.zip'\n",
        "download = session.get(zip_url)\n",
        "z = zipfile.ZipFile(io.BytesIO(download.content))\n",
        "z.extractall()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XLrjVWcybiq"
      },
      "source": [
        "tracklets.json is a file that contains vehicle tracklets, obtained by running a tracking algorithm\n",
        "to track vehicles in a video file. This file contains multiple tracklets, each tracklet is supposed to correspond\n",
        "to one vehicle in the video. Each tracklet is associated with a numerical ID, the vehicle class (among: car,\n",
        "bike, bus, truck, others), and a list of detections. Each detection is a 5-tuple, where the first entry is the\n",
        "frame number of the video, and the last four entries are the x; y coordinates of the detected bounding box.\n",
        "Specifically, the first 2 coordinates correspond to the x; y coordinates of the top left corner of the detected\n",
        "bounding box and the next 2 coordinates correspond to the x; y coordinates of the bottom right corner of the\n",
        "detected bounding box."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt7zRtGNza20"
      },
      "source": [
        "import random\n",
        "import collections\n",
        "import copy\n",
        "import argparse\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "import cv2\n",
        "\n",
        "class TrackletClustering(object):\n",
        "    tracklet_database = []\n",
        "    centroids = []\n",
        "\n",
        "    def __init__(self, num_cluster):\n",
        "        self.num_cluster = num_cluster\n",
        "\n",
        "    def convert_tracklet_feature(self, tracklet):\n",
        "        \"\"\"\n",
        "        using the vector connecting the centers of the first and last detected bounding boxes in the tracklet\n",
        "        \"\"\"\n",
        "        category = tracklet['class']\n",
        "        vehicle_type = None\n",
        "        if category == 'car':\n",
        "            vehicle_type = 0\n",
        "        elif category == 'bike':\n",
        "            vehicle_type = 1\n",
        "        if category == 'bus':\n",
        "            vehicle_type = 2\n",
        "        if category == 'truck':\n",
        "            vehicle_type = 3\n",
        "        if category == 'others':\n",
        "            vehicle_type = 4\n",
        "\n",
        "        first_point = tracklet['tracks'][0]\n",
        "        last_point = tracklet['tracks'][-1]\n",
        "        x1 = (first_point[0] + first_point[2]) / 2\n",
        "        y1 = (first_point[1] + first_point[3]) / 2\n",
        "\n",
        "        x2 = (last_point[0] + last_point[2]) / 2\n",
        "        y2 = (last_point[1] + last_point[3]) / 2\n",
        "\n",
        "        feature_list = np.array([vehicle_type, tracklet['length'], x1, y1, x2, y2])\n",
        "        feature_list = np.array([x1, y1, x2, y2])\n",
        "        return feature_list\n",
        "\n",
        "    # Used to convert index list to python dict with key as centroid of cluster k\n",
        "    # and value as array of indices of features in that centroid\n",
        "    def convert_index_list_dict(self, ind_list, k):\n",
        "        classifications = {}\n",
        "        for i in range(k):\n",
        "            classifications[i] = []\n",
        "\n",
        "        # append index value based on key of classifications dict\n",
        "        for index, ind_value in enumerate(ind_list):\n",
        "            classifications[ind_value].append(index)\n",
        "\n",
        "        return classifications\n",
        "\n",
        "    def add_tracklet(self, tracklet):\n",
        "        \"Add a new tracklet into the database\"\n",
        "        feature_list = self.convert_tracklet_feature(tracklet)\n",
        "        self.tracklet_database.append(feature_list)\n",
        "\n",
        "    def build_clustering_model(self):\n",
        "        \"Perform clustering algorithm\"\n",
        "        x_train = np.array(self.tracklet_database)\n",
        "        prev_ind_list = []\n",
        "        self.centroids = [x_train[initial] for initial in range(self.num_cluster)]\n",
        "        for epoch in range(100):\n",
        "            ind_list = []\n",
        "            for feature in x_train:  # Runs X.shape[0] == n times\n",
        "                distances = [np.linalg.norm(feature - centroid) for centroid in self.centroids]\n",
        "                least_distance = min(distances)  # Data-point is assigned to centroid having least distance\n",
        "                classification = distances.index(least_distance)\n",
        "                ind_list.append(classification)\n",
        "\n",
        "            classifications = self.convert_index_list_dict(ind_list, self.num_cluster)  # re-initialize classifications for each iteration\n",
        "            print(\"Epoch \", epoch)\n",
        "            if collections.Counter(prev_ind_list) == collections.Counter(ind_list):\n",
        "                print(\"The assignment list has not changed, thus converged!\")\n",
        "                break\n",
        "            prev_ind_list = copy.deepcopy(ind_list)\n",
        "\n",
        "            # prev_centroids = copy.deepcopy(centroids)\n",
        "            # assign new centroid, change mu, Recenter step\n",
        "            for classification in classifications:\n",
        "                new_mean = np.average(x_train[classifications[classification]], axis=0)\n",
        "                self.centroids[classification] = new_mean\n",
        "        self.centroids = np.array(self.centroids)\n",
        "        self.kmeans_sklearn = KMeans(n_clusters=self.num_cluster)\n",
        "        self.kmeans_sklearn.fit(x_train)\n",
        "\n",
        "    def get_cluster_id(self, tracklet):\n",
        "        \"\"\"\n",
        "        Assign the cluster ID for a tracklet. This function must return a non-negative integer <= num_cluster\n",
        "        \"\"\"\n",
        "        centroids = self.centroids  # Not giving very good clustering video at end\n",
        "        centroids = self.kmeans_sklearn.cluster_centers_\n",
        "        feature_vector = self.convert_tracklet_feature(tracklet)\n",
        "        distances = [np.linalg.norm(feature_vector - centroid) ** 2 for centroid in centroids]\n",
        "        least_distance = min(distances)  # Data-point is assigned to centroid having least distance\n",
        "        classification = distances.index(least_distance)\n",
        "        return classification + 1\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgmxJGjJyc-a",
        "outputId": "93bdcb7a-571c-4c9d-a5c9-21cba83c1d78"
      },
      "source": [
        "cluster_list = [2,4,3]\n",
        "tracklet_file_list = ['/content/data/cam_04_debug.json','/content/data/cam_10_debug.json','/content/data/cam_16_debug.json']\n",
        "\n",
        "for i in range(3):\n",
        "  clust_obj = TrackletClustering(cluster_list[i])\n",
        "\n",
        "  with open(tracklet_file_list[i]) as f:\n",
        "      vehicle_data = json.load(f)\n",
        "  # Gather the data\n",
        "  print(\"First pass over data to gather all tracklets\")\n",
        "  for v_id in tqdm(vehicle_data):\n",
        "      v_tracklet = vehicle_data[v_id]\n",
        "      clust_obj.add_tracklet(v_tracklet)\n",
        "\n",
        "  # build clustering model\n",
        "  clust_obj.build_clustering_model()\n",
        "\n",
        "  # perform assignment\n",
        "  print(\"Second pass over data to assign tracklets to clusters\")\n",
        "  for v_id in tqdm(vehicle_data):\n",
        "      v_tracklet = vehicle_data[v_id]\n",
        "      v_tracklet[\"direction_id\"] = clust_obj.get_cluster_id(v_tracklet) # obtain cluster id and update the data file\n",
        "\n",
        "  dir_path = os.path.dirname(tracklet_file_list[i])\n",
        "  out_tracket_file = \"{}/out_{}\".format(dir_path, os.path.basename(tracklet_file_list[i]))\n",
        "\n",
        "  # save the results to output data file\n",
        "  with open(out_tracket_file, \"w\") as f:\n",
        "      json.dump(vehicle_data, f, indent=4)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 422/422 [00:00<00:00, 74629.86it/s]\n",
            "100%|██████████| 422/422 [00:00<00:00, 17944.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "First pass over data to gather all tracklets\n",
            "Epoch  0\n",
            "Epoch  1\n",
            "Epoch  2\n",
            "Epoch  3\n",
            "Epoch  4\n",
            "Epoch  5\n",
            "Epoch  6\n",
            "The assignment list has not changed, thus converged!\n",
            "Second pass over data to assign tracklets to clusters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1775/1775 [00:00<00:00, 136031.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "First pass over data to gather all tracklets\n",
            "Epoch  0\n",
            "Epoch  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  2\n",
            "Epoch  3\n",
            "Epoch  4\n",
            "Epoch  5\n",
            "Epoch  6\n",
            "Epoch  7\n",
            "Epoch  8\n",
            "Epoch  9\n",
            "Epoch  10\n",
            "Epoch  11\n",
            "Epoch  12\n",
            "Epoch  13\n",
            "Epoch  14\n",
            "Epoch  15\n",
            "Epoch  16\n",
            "Epoch  17\n",
            "Epoch  18\n",
            "Epoch  19\n",
            "Epoch  20\n",
            "Epoch  21\n",
            "Epoch  22\n",
            "Epoch  23\n",
            "Epoch  24\n",
            "Epoch  25\n",
            "Epoch  26\n",
            "Epoch  27\n",
            "Epoch  28\n",
            "Epoch  29\n",
            "Epoch  30\n",
            "Epoch  31\n",
            "Epoch  32\n",
            "The assignment list has not changed, thus converged!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1775/1775 [00:00<00:00, 22376.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Second pass over data to assign tracklets to clusters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 974/974 [00:00<00:00, 117995.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "First pass over data to gather all tracklets\n",
            "Epoch  0\n",
            "Epoch  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  2\n",
            "Epoch  3\n",
            "Epoch  4\n",
            "Epoch  5\n",
            "Epoch  6\n",
            "Epoch  7\n",
            "Epoch  8\n",
            "Epoch  9\n",
            "Epoch  10\n",
            "Epoch  11\n",
            "Epoch  12\n",
            "Epoch  13\n",
            "Epoch  14\n",
            "Epoch  15\n",
            "Epoch  16\n",
            "Epoch  17\n",
            "Epoch  18\n",
            "Epoch  19\n",
            "Epoch  20\n",
            "Epoch  21\n",
            "Epoch  22\n",
            "Epoch  23\n",
            "Epoch  24\n",
            "Epoch  25\n",
            "Epoch  26\n",
            "Epoch  27\n",
            "Epoch  28\n",
            "Epoch  29\n",
            "Epoch  30\n",
            "The assignment list has not changed, thus converged!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 974/974 [00:00<00:00, 13604.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Second pass over data to assign tracklets to clusters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn-hrid3yEup"
      },
      "source": [
        "Below function is used to visualize the results in video form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofXGnmUWs-hy"
      },
      "source": [
        "def disp_vehicles(vehicle_file, input_video, output_video):\n",
        "    with open(vehicle_file) as f:\n",
        "        vehicle_data = json.load(f)\n",
        "\n",
        "    disp_data = {}\n",
        "    max_cluster_id = 0\n",
        "\n",
        "    print(\"Processing tracklets\")\n",
        "    for v_id in tqdm(vehicle_data):\n",
        "        v_tracklet = vehicle_data[v_id]\n",
        "        v_class = v_tracklet[\"class\"]\n",
        "        if \"direction_id\" in v_tracklet:\n",
        "            v_cluster_id = v_tracklet[\"direction_id\"]\n",
        "            assert v_cluster_id >=0, \"direction_id cannot be negative\"\n",
        "            max_cluster_id = max(max_cluster_id, v_cluster_id)\n",
        "        else:\n",
        "            v_cluster_id = 0\n",
        "\n",
        "        for v_det in v_tracklet[\"tracks\"]:\n",
        "            frm_id = v_det[0]\n",
        "            bbox = v_det[1:]\n",
        "\n",
        "            disp_info = [v_id, v_class, v_cluster_id, bbox]\n",
        "\n",
        "            if frm_id in disp_data:\n",
        "                disp_data[frm_id].append(disp_info)\n",
        "            else:\n",
        "                disp_data[frm_id] = [disp_info]\n",
        "\n",
        "    cam = cv2.VideoCapture(input_video)\n",
        "    fps = cam.get(cv2.CAP_PROP_FPS)\n",
        "    width = cam.get(cv2.CAP_PROP_FRAME_WIDTH)  # float\n",
        "    height = cam.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "    out_video = cv2.VideoWriter(output_video, fourcc, int(fps), (int(width), int(height)))\n",
        "    num_frames = int(cam.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # create colormap for clusters\n",
        "    num_cluster = max_cluster_id + 1\n",
        "    colors = [(0, 0, 255), (255, 0, 0), (0, 255, 0), (255, 255, 0), (255, 0, 255), (0, 255, 255), (128, 128, 128)]\n",
        "    if num_cluster > 7: # add random colors\n",
        "        for i in range(7, num_cluster):\n",
        "            color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
        "            colors.append(color)\n",
        "\n",
        "    print(\"Rendering video frames\")\n",
        "    frm_id = 0\n",
        "    for _ in tqdm(range(num_frames)):\n",
        "        _, im = cam.read()\n",
        "        if im is None:\n",
        "            continue\n",
        "        frm_id += 1\n",
        "\n",
        "        if frm_id in disp_data:\n",
        "            vehicles2disp = disp_data[frm_id]\n",
        "\n",
        "            for vehicle in vehicles2disp:\n",
        "                bbox = vehicle[3]\n",
        "                bbox2 = [int(x) for x in bbox]\n",
        "                cluster_id = vehicle[2]\n",
        "                color = colors[cluster_id]\n",
        "                start_point = (bbox2[0], bbox2[1])\n",
        "                end_point = (bbox2[2], bbox2[3])\n",
        "                thickness = 2\n",
        "                im = cv2.rectangle(im, start_point, end_point, color, thickness)\n",
        "                if cluster_id == 0:\n",
        "                    im = cv2.putText(im, \"Outlier: {} {}\".format(vehicle[1], vehicle[0]), (bbox2[0], bbox2[1]),\n",
        "                                     cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "                else:\n",
        "                    im = cv2.putText(im, \"{} {}\".format(vehicle[1], vehicle[0]), (bbox2[0], bbox2[1]),\n",
        "                                     cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
        "\n",
        "        out_video.write(im)\n",
        "\n",
        "    out_video.release()\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93Uuovag04ez"
      },
      "source": [
        "output_tracklet_file_list = ['/content/data/out_cam_04_debug.json','/content/data/out_cam_10_debug.json','/content/data/out_cam_16_debug.json']\n",
        "input_video_list = ['/content/data/cam_04_debug.mp4','/content/data/cam_10_debug.mp4','/content/data/cam_16_debug.mp4']\n",
        "output_video_list = ['/content/data/out_cam_04_debug.mp4','/content/data/out_cam_10_debug.mp4','/content/data/out_cam_16_debug.mp4']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWHnAnN6x-Fq",
        "outputId": "88bebf05-a04b-4393-84ca-34ea412719a8"
      },
      "source": [
        "for i in range(3):\n",
        "  disp_vehicles(output_tracklet_file_list[i], input_video_list[i], output_video_list[i])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 422/422 [00:00<00:00, 23522.17it/s]\n",
            "  0%|          | 0/1208 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing tracklets\n",
            "Rendering video frames\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1208/1208 [00:14<00:00, 81.82it/s]\n",
            " 25%|██▍       | 443/1775 [00:00<00:00, 4072.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing tracklets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1775/1775 [00:00<00:00, 6945.07it/s]\n",
            "  1%|          | 7/1200 [00:00<00:20, 58.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Rendering video frames\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1200/1200 [00:19<00:00, 61.83it/s]\n",
            "100%|██████████| 974/974 [00:00<00:00, 44785.10it/s]\n",
            "  1%|          | 8/1200 [00:00<00:15, 77.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing tracklets\n",
            "Rendering video frames\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1200/1200 [00:15<00:00, 79.01it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}
